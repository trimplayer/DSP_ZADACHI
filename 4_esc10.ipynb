{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee47cea1-e00c-4ce9-9a2c-c01f3e09b70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from: https://github.com/iShkiper/DSP_24.M20_21/blob/main/%D0%9A%D0%BE%D0%B4/1.2%20STFT_on.ipynb\n",
    "#dataset: https://dataverse.harvard.edu/file.xhtml?persistentId=doi:10.7910/DVN/YDEPUT/B3VNQW&version=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f0903e2-0c3e-4ef0-879b-848881c7c011",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import librosa\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "\n",
    "# Параметры аудио и STFT\n",
    "SR = 44000\n",
    "DURATION = 5.0          # фиксированная длительность в секундах\n",
    "MAX_LEN = int(SR * DURATION)  # максимальная длина сигнала в сэмплах\n",
    "N_FFT = 1024\n",
    "HOP_LENGTH = 256\n",
    "\n",
    "# Путь к папке с датасетом ESC-10\n",
    "DATA_DIR = \"./ESC-10\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5e0d9fd-c494-473b-b68c-79431654f831",
   "metadata": {},
   "outputs": [],
   "source": [
    " #Загружаем аудио и получаем сырые данные и метки\n",
    "def load_data_and_labels(data_dir, sr=SR, max_len=MAX_LEN):\n",
    "    file_paths = glob.glob(os.path.join(data_dir, \"*\", \"*.ogg\"))\n",
    "    data = []\n",
    "    for path in file_paths:\n",
    "        label = os.path.basename(os.path.dirname(path))\n",
    "        # загружаем аудио сигнал\n",
    "        signal, fs = librosa.load(path, sr=sr)\n",
    "        # приводим сигнал к фиксированной длине max_len\n",
    "        if len(signal) < max_len:\n",
    "            # дополняем нулями в конец\n",
    "            pad_width = max_len - len(signal)\n",
    "            signal = np.pad(signal, (0, pad_width), mode='constant')\n",
    "        else:\n",
    "            # обрезаем до max_len\n",
    "            signal = signal[:max_len]\n",
    "        data.append({\"signal\": signal, \"label\": label})\n",
    "    df = pd.DataFrame(data).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Создаём DataFrame с сырыми сигналами\n",
    "df = load_data_and_labels(DATA_DIR)\n",
    "\n",
    "# Преобразуем метки в числовые индексы\n",
    "classes = sorted(df['label'].unique())\n",
    "class_to_idx = {c: i for i, c in enumerate(classes)}\n",
    "df['label_idx'] = df['label'].map(class_to_idx)\n",
    "\n",
    "# Разбиваем на train и test\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=0.2,\n",
    "    stratify=df['label_idx'],\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0582edfc-0fab-4bc4-b093-d0d92a65644e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STFT\n",
    "def compute_log_spectrogram(signal, n_fft=N_FFT, hop_length=HOP_LENGTH):\n",
    "    spec = np.abs(librosa.stft(signal, n_fft=n_fft, hop_length=hop_length))\n",
    "    log_spec = np.log1p(spec)\n",
    "    return log_spec.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6413c23c-2067-4bc1-8aeb-31a2c7f83bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.axis('off') # no axis\n",
    "#librosa.display.specshow(librosa.amplitude_to_db(X_train_stft[0],ref=np.max))\n",
    "#plt.colorbar(format='%+2.0f dB')\n",
    "#plt.title('ОПФ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff1fc650-3cb9-4f47-ba0e-d4327e014862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class ESC10Dataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.signals = df['signal'].tolist()\n",
    "        self.labels = df['label_idx'].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        spec = compute_log_spectrogram(self.signals[idx])\n",
    "        spec = np.expand_dims(spec, axis=0)\n",
    "        return torch.from_numpy(spec), self.labels[idx]\n",
    "\n",
    "# Создаем загрузчики батчей\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(ESC10Dataset(train_df), batch_size=batch_size, shuffle=True)\n",
    "test_loader  = DataLoader(ESC10Dataset(test_df),  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73fc2317-378e-4c9b-be07-c56f37e687cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Определяем модель\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(64, 128, 3, padding=1), nn.ReLU(), nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        self.classifier = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8cce6fb-ffe1-4d83-bb65-6c57963ede6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Инициализация\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#device = torch.device(\"cpu\")\n",
    "model = ConvNet(num_classes=len(classes)).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f38c31-9555-4b2c-be85-b50db15b1078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функции обучения и оценки\n",
    "def train_epoch(model, loader):\n",
    "    model.train()\n",
    "    loss_sum, correct, total = 0, 0, 0\n",
    "    for x, y in loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(out, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()*x.size(0)\n",
    "        preds = out.argmax(dim=1)\n",
    "        correct += (preds==y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "\n",
    "def eval_epoch(model, loader):\n",
    "    model.eval()\n",
    "    loss_sum, correct, total = 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            loss = criterion(out, y)\n",
    "            loss_sum += loss.item()*x.size(0)\n",
    "            preds = out.argmax(dim=1)\n",
    "            correct += (preds==y).sum().item()\n",
    "            total += x.size(0)\n",
    "    return loss_sum/total, correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3380c89b-a9c5-4d5c-9856-0c46ab354010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: train_loss=1.5298, train_acc=0.3937, val_loss=1.4034, val_acc=0.4875\n",
      "Epoch 2/50: train_loss=1.4312, train_acc=0.4594, val_loss=1.2792, val_acc=0.4875\n",
      "Epoch 3/50: train_loss=1.3880, train_acc=0.4938, val_loss=1.2520, val_acc=0.4875\n",
      "Epoch 4/50: train_loss=1.3477, train_acc=0.4750, val_loss=1.1735, val_acc=0.6125\n",
      "Epoch 5/50: train_loss=1.2341, train_acc=0.5781, val_loss=1.1439, val_acc=0.5625\n",
      "Epoch 6/50: train_loss=1.1556, train_acc=0.6031, val_loss=1.1159, val_acc=0.5375\n",
      "Epoch 7/50: train_loss=1.2652, train_acc=0.5094, val_loss=1.1425, val_acc=0.5250\n",
      "Epoch 8/50: train_loss=1.1804, train_acc=0.5500, val_loss=1.0555, val_acc=0.6625\n",
      "Epoch 9/50: train_loss=1.1340, train_acc=0.5875, val_loss=0.9817, val_acc=0.5625\n",
      "Epoch 10/50: train_loss=1.0495, train_acc=0.6125, val_loss=1.0410, val_acc=0.6750\n",
      "Epoch 11/50: train_loss=1.0500, train_acc=0.6156, val_loss=0.9948, val_acc=0.5500\n",
      "Epoch 12/50: train_loss=1.0324, train_acc=0.5969, val_loss=0.9791, val_acc=0.6500\n",
      "Epoch 13/50: train_loss=0.9932, train_acc=0.6188, val_loss=0.9370, val_acc=0.5750\n",
      "Epoch 14/50: train_loss=0.9304, train_acc=0.6344, val_loss=1.0158, val_acc=0.5250\n",
      "Epoch 15/50: train_loss=1.0217, train_acc=0.6031, val_loss=0.8388, val_acc=0.7000\n",
      "Epoch 16/50: train_loss=0.8923, train_acc=0.6813, val_loss=0.9429, val_acc=0.6000\n",
      "Epoch 17/50: train_loss=0.9502, train_acc=0.6156, val_loss=0.9309, val_acc=0.5625\n",
      "Epoch 18/50: train_loss=1.0095, train_acc=0.6281, val_loss=1.0483, val_acc=0.6750\n",
      "Epoch 19/50: train_loss=0.9297, train_acc=0.6656, val_loss=0.8632, val_acc=0.6750\n",
      "Epoch 20/50: train_loss=0.8643, train_acc=0.6375, val_loss=0.7748, val_acc=0.7250\n",
      "Epoch 21/50: train_loss=0.8582, train_acc=0.6438, val_loss=0.8201, val_acc=0.7250\n",
      "Epoch 22/50: train_loss=0.8028, train_acc=0.7031, val_loss=0.7017, val_acc=0.7625\n",
      "Epoch 23/50: train_loss=0.8427, train_acc=0.6906, val_loss=0.6871, val_acc=0.7875\n",
      "Epoch 24/50: train_loss=0.7730, train_acc=0.7094, val_loss=0.6907, val_acc=0.7500\n",
      "Epoch 25/50: train_loss=0.7730, train_acc=0.6750, val_loss=0.6869, val_acc=0.7750\n",
      "Epoch 26/50: train_loss=0.7525, train_acc=0.7156, val_loss=0.6330, val_acc=0.8125\n",
      "Epoch 27/50: train_loss=0.7505, train_acc=0.7219, val_loss=0.6947, val_acc=0.7500\n",
      "Epoch 28/50: train_loss=0.7159, train_acc=0.7281, val_loss=0.6162, val_acc=0.8625\n",
      "Epoch 29/50: train_loss=0.7333, train_acc=0.7375, val_loss=0.8506, val_acc=0.7000\n",
      "Epoch 30/50: train_loss=0.7147, train_acc=0.7156, val_loss=0.6575, val_acc=0.7500\n",
      "Epoch 31/50: train_loss=0.6802, train_acc=0.7250, val_loss=0.6185, val_acc=0.8000\n",
      "Epoch 32/50: train_loss=0.6585, train_acc=0.7344, val_loss=0.6050, val_acc=0.7500\n",
      "Epoch 33/50: train_loss=0.6729, train_acc=0.7531, val_loss=0.7637, val_acc=0.7125\n",
      "Epoch 34/50: train_loss=0.7296, train_acc=0.7125, val_loss=0.5515, val_acc=0.8375\n",
      "Epoch 35/50: train_loss=0.6732, train_acc=0.7312, val_loss=0.5394, val_acc=0.8750\n",
      "Epoch 36/50: train_loss=0.6443, train_acc=0.7812, val_loss=0.5769, val_acc=0.8000\n",
      "Epoch 37/50: train_loss=0.6092, train_acc=0.7719, val_loss=0.5781, val_acc=0.7875\n",
      "Epoch 38/50: train_loss=0.6080, train_acc=0.7875, val_loss=0.4970, val_acc=0.8250\n",
      "Epoch 39/50: train_loss=0.6222, train_acc=0.7250, val_loss=0.5876, val_acc=0.7875\n",
      "Epoch 40/50: train_loss=0.5811, train_acc=0.7812, val_loss=0.6238, val_acc=0.7875\n",
      "Epoch 41/50: train_loss=0.6654, train_acc=0.7438, val_loss=0.6020, val_acc=0.8125\n",
      "Epoch 42/50: train_loss=0.6015, train_acc=0.7719, val_loss=0.5097, val_acc=0.8750\n",
      "Epoch 43/50: train_loss=0.6060, train_acc=0.7625, val_loss=0.4794, val_acc=0.8625\n",
      "Epoch 44/50: train_loss=0.5719, train_acc=0.7438, val_loss=0.6602, val_acc=0.8000\n",
      "Epoch 45/50: train_loss=0.6005, train_acc=0.7625, val_loss=0.5551, val_acc=0.8125\n",
      "Epoch 46/50: train_loss=0.5536, train_acc=0.7875, val_loss=0.5267, val_acc=0.8625\n",
      "Epoch 47/50: train_loss=0.5566, train_acc=0.8031, val_loss=0.6314, val_acc=0.8250\n",
      "Epoch 48/50: train_loss=0.6351, train_acc=0.7594, val_loss=0.6345, val_acc=0.7750\n",
      "Epoch 49/50: train_loss=0.5851, train_acc=0.7656, val_loss=0.5339, val_acc=0.8250\n",
      "Epoch 50/50: train_loss=0.5551, train_acc=0.7844, val_loss=0.5672, val_acc=0.8000\n"
     ]
    }
   ],
   "source": [
    "# Тренировочный цикл\n",
    "epochs = 50\n",
    "for epoch in range(1, epochs+1):\n",
    "    tr_loss, tr_acc = train_epoch(model, train_loader)\n",
    "    val_loss, val_acc = eval_epoch(model, test_loader)\n",
    "    print(f\"Epoch {epoch}/{epochs}: train_loss={tr_loss:.4f}, train_acc={tr_acc:.4f}, \"\n",
    "          f\"val_loss={val_loss:.4f}, val_acc={val_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81092af3-cdf6-46f5-9517-2a47a553bd1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
